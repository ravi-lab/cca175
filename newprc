sqoop import --connect "jdbc:mysql://ms.itversity.com/retail_db" \
--username retail_user \
--password itversity \
--table orders \
--target-dir /user/raviteja/problem1/orders \
--as-avrodatafile  \
--compress \
--compression-codec  org.apache.hadoop.io.compress.SnappyCodec \

sqoop import --connect "jdbc:mysql://ms.itversity.com/retail_db" \
--username retail_user \
--password itversity \
--table order_items \
--target-dir /user/raviteja/problem1/order_items \
--as-avrodatafile  \
--compress \
--compression-codec  org.apache.hadoop.io.compress.SnappyCodec \

// import avro data into data frames 

import com.databricks.spark.avro._;
val ordersDF=sqlContext.read.avro("/user/raviteja/problem1/orders")
val order_itemsDF=sqlContext.read.avro("/user/raviteja/problem1/order_items")

val order_JoinDF=ordersDF.join(order_itemsDF,ordersDF("order_id")===order_itemsDF("order_item_order_id"))
order_JoinDF.registerTempTable("ordJoin")

val res=sqlContext.sql("select to_date(from_unixtime(cast(order_date/1000 as int))) as datef, order_status, cast(sum(order_item_subtotal) as DECIMAL(10,2)) as amt , count(distinct(order_id)) as total_orders from ordJoin group by to_date(from_unixtime(cast(order_date/1000 as int))),order_status")
res.registerTempTable("res")
var sqlResult = sqlContext.sql("select to_date(from_unixtime(cast(order_date/1000 as bigint))) as order_formatted_date, order_status, cast(sum(order_item_subtotal) as DECIMAL (10,2)) as total_amount, count(distinct(order_id)) as total_orders from ordJoin group by to_date(from_unixtime(cast(order_date/1000 as bigint))), order_status order by order_formatted_date desc,order_status,total_amount desc, total_orders");
res.registerTempTable("res")
sqlContext.setConf("spark.sql.parquet.compression.codec","gzip")

res.write.parquet("/user/raviteja/problem1/result4b")

mysql -u retail_user -h "ms.itversity.com" -p itversity

create table raviteja_result(order_date varchar(255) not null,order_status varchar(255) not null, total_orders int, total_amount numeric, constraint pk_order_result primary key (order_date,order_status)); 

sqoop export \
--table raviteja_result \
--connect "jdbc:mysql://ms.itversity.com/retail_export" \
--username retail_user \
--password itversity \
--export-dir "/user/raviteja/problem1/result4bcsv" \
--columns "order_date,order_status,total_amount,total_orders" \
--m 1


val ord=sqlContext.read.parquet("/user/raviteja/problem1/result4b")

val ordcsv=res.map(o=> o(0)+","+o(1)+","+o(2)+","+o(3))
res2.map(x=> x(0) + "," + x(1) + "," + x(2) + "," + x(3)).saveAsTextFile("/user/raviteja/problem1/result4b2csv")

sqlContext.sql("select * from res where datef="2013-09-03").show